{
 "metadata": {
  "name": "",
  "signature": "sha256:398853f4109611c60e64e6c998a27f03cf26dfdcfaf0d75351f2b449c3fb4790"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import nbprep\n",
      "nbprep.style()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# HDF Files and Network Graphs\n",
      "\n",
      "*Note: To run this example, a separate file \"gaussian.h5\" must be uploaded to the folder \"static\" in the notebook directory. This file can be found in the folder \"Notebook Extras\", which in turn is found in the Google Drive link that I've provided. See the Getting Started slides for information on uploading files.*\n",
      "\n",
      "This notebook reproduces an analysis from a collaborative research project between myself and my colleague [Prof. Benjamin Gorske at Bowdoin College](http://www.bowdoin.edu/faculty/b/bgorske/), the results of which were published in a [recent manuscript](http://pubs.acs.org/doi/abs/10.1021/jo4014113?journalCode=joceah). The final figure, shown below, can be found in the [Supporting Information](http://pubs.acs.org/doi/suppl/10.1021/jo4014113) for the paper, and was crucial for the final interpretation of the data. The code in this notebook represents a great deal of work on my part, and the complexity of the code reflects that effort. I did my best to minimize my original code to the most important features and to explain as much as I can along the way.\n",
      "\n",
      "<img src=\"static/nbo_mat3.png\" style=\"width:90%;\">\n",
      "\n",
      "## Desciption of the problem\n",
      "\n",
      "Subtle changes in chemical structure can sometimes have drastic consequences for reactivity. My colleague Prof. Gorske is studying [peptoids](http://en.wikipedia.org/wiki/Peptoid) -- which are analogous to peptides, one of Nature's building blocks -- but they possess some unusal and pretty cool properties. Prof. Gorske's [previously developed model systems](http://pubs.acs.org/doi/abs/10.1021/ja071310l), and demonstrated that subtle changes in the chemical composition of these models produced drastic differences in reactivity. An example of one of these model systems is shown below.\n",
      "\n",
      "<img src=\"static/peptoid.svg\" style=\"width:20%;\">\n",
      "\n",
      "In this particular model, removing the \"NO<sub>2</sub>\" group drastically changes the geometric preference at the amide (N-C=O) or thioamide (N-S=O) group on the other end of the ring. \n",
      "\n",
      "*How are these compositional changes at one end of the molecule affecting properties at the other end?* We postulated that there was a electronic connectivity network between the \"NO<sub>2</sub>\" and the (thio)amide. To do this, I worked on calculating some special type of theoretical electon orbitals called [Natural Bond Orbitals (NBO)](http://en.wikipedia.org/wiki/Natural_bond_orbital). NBOs are localized on certain fragments of the molecule; however, they can interact with each other in ways that stabilize the overall molecular structure. An example of this interaction is shown in the picture below -- an animated movie can be found in the shared folder.\n",
      "\n",
      "<img src=\"static/020.png\" style=\"width:50%;\">\n",
      "\n",
      "In this picture, the transparent blue and red lobes represent one NBO and the green and yellow lobes represent another NBO. The interaction/overlap of these orbitals leads to an overall stabilization of this molecule. These NBO-NBO interactions form a very large and complicated *connectivity network*. In order to analyze this efficiently, I used Python's network analysis library [NetworkX](https://networkx.github.io/). \n",
      "\n",
      "There was another problem that needed to be addressed as well -- handling the large amounts of data. Prof. Gorske had synthesized several of these molecules, and for the theoretical analysis, multiple calculations for each model compound needed to be run and compared. I generated somewhere around 650 MB of *compressed* output files that I needed to parse. (These are compressed versions of the Gaussian output files from by Text Parsing notebook.) The details of that procedure are beyond the scope of this example, but after extracting the information from the output files, I needed a convenient way to store and access the data. \n",
      "\n",
      "To this end, I chose the open-source [Hierarchical Data Format (HDF) file format](http://en.wikipedia.org/wiki/Hierarchical_Data_Format). These files are specifically designed for high-performance storage and access of very large scientific data sets. Python has at least two libraries for these files [PyTables](http://www.pytables.org/moin) and [h5py](http://www.h5py.org/) -- I chose PyTables for my analysis."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting started\n",
      "\n",
      "This prodedure requires the external libraries Numpy, Matplotlib, NetworkX, and PyTables (tables)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.colors as plc\n",
      "import matplotlib.collections as mpc\n",
      "import networkx as nx\n",
      "import tables as pyt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I'm setting some default parameters for my plots, so that they have the appearance that I like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rc('font', size=16.0)\n",
      "plt.rc('mathtext', default='regular')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several parameters that will control our output.\n",
      "\n",
      "* `h5_file`: The location of the HDF file with my data\n",
      "* `expt_num`: The experiment that I'd like to process in this example\n",
      "* `center`: These are the NBOs that will form the center of my network plot\n",
      "* `N`: Number of layers in the network plot\n",
      "* `cutoff`: An energy cutoff, this is explained more later\n",
      "* `scale`: Scaling factor for our network graph, more below\n",
      "* `scale_axis`: This just scales the network plot at the end so it fits in the window"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h5_file='static/gaussian.h5'\n",
      "expt_num = 'rcn0001_020'\n",
      "\n",
      "center = ['BD*( 2) C 6- C 7', 'BD ( 2) C 6- C 7',\n",
      "        'BD*( 2) C 8- C 9', 'BD ( 2) C 8- C 9',\n",
      "        'BD*( 2) C10- C11', 'BD ( 2) C10- C11',\n",
      "        ]\n",
      "\n",
      "N = 2 \n",
      "cutoff = 7. \n",
      "scale = 5.0\n",
      "scale_axes = 0.85 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 1. Load the data\n",
      "\n",
      "The first thing we need to do is extract the relevant data from our large HDF file. In general, HDF files are organized like a tree. There is a root \"folder\" (/) at the base, that can contain things like data Tables (spreadsheet-like), Arrays (multi-dimmensional blocks of numbers), and indiviual values as well (for flags, etc.). To better organize the data in the file, you can made Groups that act like folders and can contain Tables, Arrays, or other Groups. Printing our open HDF file shows us the structure of this particular file. *Important Note:* Even though we've opened and are accessing the HDF file, it is not read entirely into memory. HDF files are designed to be quickly and efficiently read from the hard disk, which is very important when you are access very large data sets that won't fit into memory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h5f = pyt.openFile(h5_file)\n",
      "print h5f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can access different elements in our file very easily using the dot (\".\") notation that is common with Python objects. Below, we are accessing the atomic coordinates of the model that we'll be working with in this example. We had to add a slice to the end (`[:]`) in order to extract the data from the file. (Otherwise, you get an [iterator](http://pytables.github.io/usersguide/tutorials.html#reading-and-selecting-data-in-a-table), which is more memory efficient way to access the data.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print h5f.root.rcn0001_020.coords\n",
      "h5f.root.rcn0001_020.coords[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This particular HDF file contains a Table called `nbo_e2` that contains >25,000 rows of NBO data that is necessary for our analysis. The columns of the table are printed below as well as the first row entry.\n",
      "\n",
      "* The first two rows provide the experiment number information\n",
      "* The fourth and sixth columns are the donor and acceptor NBO, respectively\n",
      "* The seventh column is the interaction energy (\"e2\") between these NBOs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbo = h5f.root.nbo_e2\n",
      "print nbo.shape\n",
      "print nbo.colnames\n",
      "print nbo[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 2. Create a Connectivity Network Graph\n",
      "Now we can create the data structure that is necessary for our network graph. In this case, we need to create a [Python dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries) that contains our connectivity data (`nx_dict = {}`). We can then iterate over all the rows of our `nbo` table using a `for` loop. If the experiment number matches the one that we selected at the beginning of our program (`expt_num`), then we can add this to our connectivity dictionary. One donor can be connected to many different acceptors with different energies, so we are ultimately creating a dictionary-of-dictionaries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx_dict = {}\n",
      "for i in nbo.iterrows():\n",
      "    expt = i['expt']+'_'+i['enum']\n",
      "    donor = i['donor']\n",
      "    accept = i['accept']\n",
      "\n",
      "    if expt == expt_num:\n",
      "        # If this donor is not in our dictionary, add a new entry\n",
      "        if not donor in nx_dict:\n",
      "            nx_dict[donor] = {accept: {'weight':i['e2']} }\n",
      "        # Or else add another connectivity node\n",
      "        else:\n",
      "            nx_dict[donor][accept] = {'weight':i['e2']}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This new data set can be difficult to visualize, so to give you an idea of what it looks like, here is one entry in our dictionary. In this case, the donor NBO `\"BD ( 1) C 1- C 2\"` is connected to four different acceptor NBOs. The weights are the energy values associated with these interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx_dict['BD ( 1) C 1- C 2']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're done with the HDF file, so we can close it now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h5f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are ready to create a connectivity network using our NBO dictionary as an input. We can also create a simple spring (force directed) graph of our data. In this case, the 'weights' (i.e. interaction energy) will dictate how much pull two points have to one another. (Think of it like a larger weight is a stronger spring holding the two points together.) The tight clustering of certain regions indicates stronger interactions between a series of NBO orbitals. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G = nx.Graph(nx_dict)\n",
      "nx.draw(G, node_size=20, with_labels=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 3. Shell Layout\n",
      "\n",
      "The graph above does contain all of our connectivity information; however, it provides no insight for the problem at hand. We are going to have to do a bit more work to get a useful plot.\n",
      "\n",
      "In order to make a [Shell Layout](http://networkx.github.io/documentation/latest/reference/generated/networkx.drawing.layout.shell_layout.html?highlight=shell_layout) graph like the one shown at the beginning of this notebook, we are going to need to accomplish the following:\n",
      "\n",
      "* Pick a center layer of NBO orbitals -- `center` variable above pick the orbitals that describe the $\\pi$ orbitals of the aromatic ring\n",
      "* Find all of the NBOs that directly interact with the central layer\n",
      "* Repeat this process until we reach the desired number of layers `N`\n",
      "* Create a Shell Layout with these layers\n",
      "* Get all of the node and edge positions\n",
      "* Use the edge weights (i.e. interaction energies) to color the edges"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 3a. Find the layers\n",
      "\n",
      "In order to find the layers, we are going to make use of [Python sets](https://docs.python.org/2/library/stdtypes.html#set). These behave much like you would expect based on set theory -- e.g. they have unions, intersections, etc. They also only contain unique items, so the following:\n",
      "\n",
      "```python\n",
      "a = set([\"A\", \"B\"])\n",
      "b = set([\"B\", \"C\"])\n",
      "a.union(b)\n",
      "``` \n",
      "\n",
      "will automatically give us a set containing only \"A\", \"B\", and \"C\" (not two copies of \"B\"). This is important for us because we only want to have unique nodes in each layer, and sets will help us accomplish that goal.\n",
      "\n",
      "In the following code, `layers` will be a list of nodes in each layer, and nodes is going to be a set of all the nodes in every layer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers = [set(center)] \n",
      "nodes = set(center)\n",
      "\n",
      "# Here `i` is going to a number corresponding to a layer number\n",
      "for i in range(N):\n",
      "    temp = []\n",
      "    # For all of the nodes in this layer, find the nodes (keys) that are connected\n",
      "    for j in layers[i]:\n",
      "        temp.extend(G[j].keys())\n",
      "    # Make sure these nodes are not in the original set\n",
      "    temp = set(temp).difference(nodes)\n",
      "    # Add these nodes as the next layer\n",
      "    layers.append(temp)\n",
      "    # Add new nodes to our total node set\n",
      "    nodes = nodes.union(temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take a look at one of our layers to see what it looks like. (Of course, `layers[0]` will be identical to our `center` variable that we set at the beginning.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 3b. Create the shell layout\n",
      "\n",
      "Here we are using NetworkX to create the shell layout of our data. We are making sure that we only use the layers that we found above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#layers = [list(n) for n in layers]\n",
      "pos = nx.shell_layout(G, layers, scale=scale)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 3c. Get the node and edge positions\n",
      "\n",
      "Looping though our shell layout (`pos`) provides us with a node name (`i`). Using this node name as a key to our shell layout (`pos[i]`) returns the position of the node as an (x, y) pair. These data can be converted to a 2D Numpy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_pos = [pos[i] for i in pos] \n",
      "node_pos = np.array(node_pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Getting the edge information is tricky. First of all, if we loop through the edges of our graph (`G`), we get a tuple like the following:\n",
      "\n",
      "    ('BD ( 1) C 2- S17', 'BD*( 1) C 2- S17', {'weight': 3.16})\n",
      "    \n",
      "Where the donor is the first item, the acceptor is the second item, and the interaction energy (labeled weight) is in the final dictionary. We can check if the first and second items are in our node list for our layered plot. If so, add this edge to our edges list and append the energy to our new energy list. Finally, convert the energy list to a Numpy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edges = []\n",
      "e2 = []\n",
      "\n",
      "for i in G.edges(data=True):\n",
      "    if i[0] in nodes and i[1] in nodes:\n",
      "        edges.append(i)\n",
      "        e2.append(i[2]['weight'])\n",
      "e2 = np.array(e2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we can use our edges list to construct an array of edge positions. (This is the starting and ending point of a line that connects the two nodes.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edge_pos = [(pos[i], pos[j]) for i, j, k in edges]\n",
      "edge_pos = np.array( edge_pos )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edge_pos.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 3d. Edge coloring\n",
      "\n",
      "In order to have the edges colored according to the energy of interaction, we need to do a couple of things. First of all, we want to cut off very large energies because they will throw off the coloring. Secondly, we need to normalize the remaining energies. (This is a requirement for Matplotlib, not necesarily for our data analysis.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find the local maximum that is at or below the cutoff. \n",
      "e2_mask = e2 <= cutoff\n",
      "lmx = e2[e2_mask].max()\n",
      "\n",
      "# Create the normalized data array.\n",
      "e2_norm = e2[ e2_mask ]/lmx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 4. Make the plot\n",
      "\n",
      "The plotting code to make this graph is rather verbose, and in this environment (SMC), all of the plotting code needs to be contained in one cell. I've done my best to annotate each chunk of plotting code. In many cases, some of this plotting stuff is much easier than this example would make it seem; however, this example does highlight the complete control that Matplotlib gives you over plotting appearance. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Create the plot ####\n",
      "\n",
      "fig = plt.figure(figsize=(12.,10.), facecolor='w')\n",
      "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
      "\n",
      "# Set up the colormap to be used for this plot. \n",
      "cmap = plt.cm.autumn_r\n",
      "colors = cmap(e2_norm)\n",
      "# Set the lines to have transparency dictated by their normalized energy.\n",
      "colors[:,3] = e2_norm\n",
      "\n",
      "# The edges with the custom colors. First set a base linewidth for all lines.\n",
      "base_lw = 5.\n",
      "# Create black lines for edges with energies above the cutoff\n",
      "lc2 = mpc.LineCollection(edge_pos[e2_mask == False], linewidths=base_lw,\n",
      "        colors='k')\n",
      "ax.add_collection(lc2)\n",
      "# Create colored lines for edges with energies below the cutoff\n",
      "lc = mpc.LineCollection(edge_pos[e2_mask], linewidths=e2_norm*base_lw,\n",
      "        colors=colors)\n",
      "ax.add_collection(lc)\n",
      "\n",
      "# Create a scatter plot of the nodes nodes.\n",
      "ax.scatter(node_pos[:,0], node_pos[:,1], s=150, zorder=1000, facecolor='0.5')\n",
      "\n",
      "# Add text labels to the nodes.\n",
      "for p, coord in pos.items():\n",
      "    fontsize = 10\n",
      "    color = 'k'\n",
      "    # If our nodes are any of these special cases, change the fontsize and color\n",
      "    if p == \"BD ( 1) C 4- H22\" or p == \"BD*( 1) C 4- H22\":\n",
      "        fontsize = 14\n",
      "        color = 'g'\n",
      "    elif p == \"LP ( 2) S17\" or p == \"BD*( 2) C 6- C 7\":\n",
      "        fontsize = 14\n",
      "        color = 'b'\n",
      "    # Add the text and make sure it is above everything else (zorder)\n",
      "    ax.text(coord[0], coord[1], p, ha='center', fontsize=fontsize, zorder=1005,\n",
      "            clip_on=True, color=color)\n",
      "\n",
      "# Create a custom colorbar ignoring the large energies. We should add a zero to \n",
      "# our energy array just so that the colorbar extends down to that number.\n",
      "mappable = plt.cm.ScalarMappable(cmap=cmap)\n",
      "mappable.set_array(np.append(e2[e2_mask], 0))\n",
      "cbar = fig.colorbar(mappable)\n",
      "cbar.set_label('NBO SOP Energy (kcal mol$^{-1}$)')\n",
      "\n",
      "# Autoscale, set limits, and remove bounding box.\n",
      "ax.autoscale()\n",
      "ax.set_xlim([i*scale_axes for i in ax.get_xlim()])\n",
      "ax.set_ylim([i*scale_axes for i in ax.get_ylim()])\n",
      "ax.set_axis_off()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Alternative to plotting\n",
      "\n",
      "As an alternative to plotting, we could have also done a shortest-path calculation. This requires that we invert the interaction energies, so that larger energies give a \"shorter\" path. In this case, we're finding the shortest distance between the donor `'LP ( 2) S17'` and the acceptor `'BD ( 2) N14- O29'`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This computes some shortest paths based on energy distributions.\n",
      "R = G.copy()\n",
      "for u,v,k in R.edges(data=True):\n",
      "    k['weight'] = 1/k['weight']\n",
      "dists = nx.dijkstra_path(R, 'LP ( 2) S17', 'BD ( 2) N14- O29')\n",
      "print dists"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Putting it all together\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}