{
 "metadata": {
  "name": "",
  "signature": "sha256:bb477be2e341a6af9d6ccd5efc5d2810a737d01489938821ed420086af8ac439"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import nbprep\n",
      "nbprep.style()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data Tables and Time Series\n",
      "\n",
      "[Pandas](http://pandas.pydata.org/) is a Python library for advanced data analysis. Probably it's most important feature are [DataFrame objects](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe), which are analogous to data.frame tables in R. DataFrames have a number of advanced SQL-like analysis capabilities -- such as table [merging](http://pandas.pydata.org/pandas-docs/stable/merging.html), [grouping, and aggregating](http://pandas.pydata.org/pandas-docs/stable/groupby.html). DataTables are highly integrated into a number of other Python packages, in particular, the statistical modeling package [statsmodels](http://statsmodels.sourceforge.net/stable/). \n",
      "\n",
      "One of the (initial) focus areas of the Pandas package is econometrics, which is due in no small part to the fact that its lead developer, [Wes McKinney](http://blog.quantopian.com/meet-quantopians-newest-advisor-wes-mckinney/), is a statistition with with a background as a quantitative analyst for the financial industry. What that means is for users is that Pandas has sophisticated tools for working with [time series data](http://pandas.pydata.org/pandas-docs/stable/timeseries.html).\n",
      "\n",
      "This toy example uses the historical Dow Jones stock prices to highlight basic DataFrame usage and several interting capabilities.\n",
      "\n",
      "## Getting started\n",
      "\n",
      "Here we'll import the Pandas library. Internally, Pandas uses [Matplotlib](http://matplotlib.org/) for making plots. There is a special option to set the default plotting style parameters to mimic the popular ggplot2 library for R. (There is now a [ggplot library for Python](http://blog.yhathq.com/posts/ggplot-for-python.html) as well.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pds\n",
      "pds.set_option('display.mpl_style', 'default')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The stock market data is contained in the file 'dji.csv' -- a segment of this file is shown below.\n",
      "\n",
      "    Historical Data Dow Jones Ind Ave\n",
      "    RCN: Got this from https://www.quandl.com/\n",
      "\n",
      "    Date,Value\n",
      "    2014-09-17,17156.85\n",
      "    2014-09-16,17131.97\n",
      "    2014-09-15,17031.14\n",
      "    2014-09-12,16987.51\n",
      "    2014-09-11,17049.0\n",
      "    \n",
      "[Pandas' `read_csv` function](http://pandas.pydata.org/pandas-docs/stable/io.html) can be used to read text input files such as comma-separated (or space-delimited) files. The first three lines of this file are simply a header with some download information, so we'll be sure to skip those (`skiprows`). The default is to read the first line as column names, so don't skip the fourth line. We want to make sure that Pandas converts any date-type columns (`parse_dates`) to [datetime objects](http://pandas.pydata.org/pandas-docs/stable/timeseries.html). Finally, we'll set the index of our table to be the \"Date\" column (`index_col`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices = pds.read_csv('static/dji.csv', skiprows=3, parse_dates=True, index_col='Date')\n",
      "prices.ix[:10] # only the first 10 rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's plot the data to see what the Dow Jones has done over time. (I should have started investing earlier!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For our next analysis, it is convenient if the dates were sorted in the opposite manner. In this case, the keyword `inplace` simply tells Pandas to change the original data set; otherwise, the default is to provide a copy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices.sort(inplace=True)\n",
      "prices.ix[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A [simple moving average (SMA)](http://www.investopedia.com/terms/m/movingaverage.asp) is a commonly used analysis technique for investors. An SMA analysis takes a specified number of data points from a list and averages them together, then the next set of 10 data points is averaged, and so on. This is continues until the data set is exhausted. Note: if you are using 10 data points to generate the first average point, you lose 9 (10-1) data points in the process.\n",
      "\n",
      "[Pandas has several builtin methods](http://pandas.pydata.org/pandas-docs/stable/computation.html) for this type of analysis, with `rolling_mean` being used for SMA. It is easy to add a new column to our table with our moving average data (`'mv_avg'`). The second number in the function call denotes the number of points that will be used for the average. Pandas automatically handles missing values (`NaN` or \"not a number\") and adjusting the rows to fit together on the proper dates. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices['mv_avg'] = pds.rolling_mean(prices['Value'], 10)\n",
      "prices.ix[:15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we make a plot of our new data. Pandas defaults to plotting both columns in our DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices.plot(xlim=('1/1/2012', '10/1/2014'), ylim=(10800, 18000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas has very powerful [builtin grouping capabilities](http://pandas.pydata.org/pandas-docs/stable/groupby.html). These are best demonstrated by example. \n",
      "\n",
      "Currently our `prices` DataFrame is daily stock prices, but we might be more interested in how the prices fluctuate on a monthly basis. You could fake this by looking at a rolling average with a window of ~20 (4 weeks x 5 days). However, each month has a different number of days, and the stock market is closed for certain holidays, etc. In this case, Pandas can group our data by the year and month (remember that this DataFrame's index is dates). We can easily calculate the mean of the data in these groups, which returns a DataFrame with a [hierarchical index](http://pandas.pydata.org/pandas-docs/stable/indexing.html#hierarchical-indexing-multiindex)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gb = prices.groupby([prices.index.year, prices.index.month])\n",
      "gb_mean = gb.mean()\n",
      "gb_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can do more advanced analyses on our groups using the [`aggregate` function](http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation). In this case, we will take our grouped stock values (`'Values'` column) and create a new hierarchical DataFrame with a column for the mean ('Mean' -- using [Numpy's `mean` function](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html)) and the standard deviation ('Std' -- using [Numpy's `std` function](http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html)). In more complex cases, we could have built our own analysis function rather than using only Numpy/Pandas builtin functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val_mean_std = gb['Value'].aggregate({'Mean': np.average, 'Std': np.std})\n",
      "val_mean_std"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}