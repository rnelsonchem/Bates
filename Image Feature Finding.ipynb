{
 "metadata": {
  "name": "",
  "signature": "sha256:7f0ae587dacd15509c1209c9140a5b8059f8af289a0c2e0c0aafc2925432483a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import nbprep\n",
      "nbprep.style()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Image Feature Finding\n",
      "\n",
      "This is fairly simple example that shows how you might write a program for feature detection in an image. This is meant to illustrate the technique, and may be a poor method to do this analysis. The dedicated image analysis library [scikit-image](http://scikit-image.org/) and the [Python bindings to the computer vision library OpenCV](http://docs.opencv.org/trunk/doc/py_tutorials/py_tutorials.html) are probably better/more advanced alternatives. I got a lot of this information from [a very interesting StackOverflow question](http://stackoverflow.com/questions/4087919/how-can-i-improve-my-paw-detection). There are also some other interesting answers in that thread. (And a very cool animation.)\n",
      "\n",
      "# Getting started.\n",
      "\n",
      "First import some extra libraries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.ndimage as spn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, I'll be using an [example image](http://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/SEM_Zoom.ogg/800px--SEM_Zoom.ogg.jpg) from [Wikipedia's article on Scanning Electron Microscopy](http://en.wikipedia.org/wiki/Scanning_electron_microscope). This is an image of a number of very small glass beads."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_orig = plt.imread('static/SEM_Zoom.ogg.jpg')\n",
      "plt.imshow(image_orig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The problem\n",
      "\n",
      "We might want to know something about the size distribution of the beads in this picture -- a painful process if done by hand -- so we might want to automate things. \n",
      "\n",
      "Before we can do this, we need to know a little bit about digital images. First of all, jpeg raster images are just a big array of pixels. For a 10 megapixel image, that array will have 10 million pixels. We can see that if we look at the shape (`image_orig.shape`) of our image. In this case, we have 720x1280 (=921,600) pixels.\n",
      "\n",
      "However, each pixel is actually composed of three values: red, green, and blue levels (hence RGB). This gives us an overall 3D array of data points. The three values for the first pixel (`image_orig[0,0]`) are also printed below. Notice that all of the values are the same. That is because this is a gray scale image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print image_orig.shape\n",
      "print image_orig[0,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because all of the RGB values are the same, our analysis will be simplified considerably by only looking at one of the three numbers. Our new `image` is a 2D array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image = image_orig[:,:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can look at a histogram of these values for the entire image (in this case, flatten the 2D array to 1D)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist = plt.hist(image.flat, bins=125)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are two distributions in the image. The lower values are darker spots: higher values are bright spots. Our beads are brighter than the background, so let's create a threshold mask (`thresh`) that cuts off all of the values below a certain level. The exact value here was found by trial-and-error, but you can see that it approximately bisects the two populations in the histogram above.\n",
      "\n",
      "A plot of this mask is only two colors: red are values greater than our threshold (`True` in this case) and blue are values below (`False`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = (image > 68)\n",
      "\n",
      "plt.imshow(thresh)\n",
      "# plt.subplot(121)\n",
      "# plt.imshow(thresh[:,:640])\n",
      "# plt.subplot(122)\n",
      "# plt.imshow(image_orig[:,:640])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scipy has a [`label` function](http://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.measurements.label.html#scipy.ndimage.measurements.label) that searches a boolean mask (like `thresh`) and counts the contiguous blocks of `True` components (individual features). `num` is the total number of features. `spheres` is a 2D array with each feature labeled using a unique id number. Feature \"0\" (zero) is the background."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spheres, num = spn.label(thresh)\n",
      "\n",
      "print num\n",
      "print spheres.shape\n",
      "print spheres"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It might be a little easier to see what is going on using an example. Here we will only consider one of the labeled features (200 in this case) by setting a variable `mask`. Next, create a 3D array of zeros (`color_sphere`). The third dimension is 4 a value RGBA array (with A = alpha or transparency, zero is fully transparent). Where our zeros array matches the position of feature 200 (`color_sphere[mask]`), we will set the color to be red with no transparency (`[1, 0, 0, 1.]`). Show the original image (`image_orig`) and overlay our partially transparent layer (`color_sphere`). Our mask is a 2D array of `True` and `False` booleans. `True` where we observe our feature; `False` everywhere else. Because `True` == 1 and `False` == 0, we can sum this mask to determine the total number of pixels that make up this sphere. If we knew a distance that one pixel represented, we could convert this sum into a real area.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = (spheres == 200)\n",
      "color_sphere = np.zeros(image.shape + (4,))\n",
      "color_sphere[mask] = [1, 0, 0, 1.]\n",
      "plt.imshow(image_orig)\n",
      "plt.imshow(color_sphere)\n",
      "print mask.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can loop through all of our features to find the areas (sum) as we did in the previous code block. However, if our sphere touches the left or right edge of the picture (`x in spheres[(0,-1),:]`) or the top or bottom edge (`x in spheres[:,(0,-1)]`), it has probably been cut off, so we will ignore the size of this feature."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sizes = []\n",
      "for x in xrange(1, num):\n",
      "    if x in spheres[(0,-1),:] or x in spheres[:,(0,-1)]:\n",
      "        sizes.append(0.)\n",
      "    else:\n",
      "        sphere = (spheres == x)\n",
      "        sphere_size = sphere.sum()\n",
      "        sizes.append(sphere_size)\n",
      "sizes = np.array(sizes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A histogram shows us the distribution of these sizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist = plt.hist(sizes, bins=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An examination of the histogram shows several important things. First of all, there are a very large number of small features. These are most likely individual pixels. There are also peaks in the distribution at 1000, 2000, 3000, etc. Remember from above that our single sphere was ~1000 pixels. That means these regions represent one sphere, two overlapping spheres, three overlapping spheres, etc. We can select only the single spheres by creating a size mask (`mask`). Let's print some simple statistics and a histogram of the selected sizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = (sizes > 400) & (sizes < 1700)\n",
      "\n",
      "print 'Number of selected features:', len(sizes[mask])\n",
      "print 'Median Size (pix):', np.median(sizes[mask])\n",
      "print 'Mean Size (pix):', np.mean(sizes[mask])\n",
      "print 'Std. Dev.:', np.std(sizes[mask])\n",
      "\n",
      "hist = plt.hist(sizes[mask], bins=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can make another semi-transparent layer of selected spheres in a similar manner to what we did before. Be sure to only select the sizes in our defined range (`sphere_nums[mask]`), and set them to be red with 75% transparency (`[1., 0., 0., 0.75]`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clear_layer = np.zeros(image.shape + (4,))\n",
      "sphere_nums = np.arange(1, num)\n",
      "for x in sphere_nums[mask]:\n",
      "    clear_layer[spheres == x] = [1., 0., 0., 0.75]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the original image with the transparent overlay."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(image_orig)\n",
      "plt.imshow(clear_layer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}